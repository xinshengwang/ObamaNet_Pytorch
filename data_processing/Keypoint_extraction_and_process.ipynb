{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "greek-maldives",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import dlib\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from skimage import io\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metropolitan-target",
   "metadata": {},
   "source": [
    "## Extract keypoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "tight-thread",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_path = \"F:/code/avatar/Pre-trained_model/shape_predictor_68_face_landmarks.dat\"\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(predictor_path)\n",
    "def get_facial_landmarks(filename):\n",
    "    image = io.imread(filename);\n",
    "    # detect face(s)\n",
    "    dets = detector(image, 1);\n",
    "    shape = np.empty([1,1])\n",
    "    for k, d in enumerate(dets):\n",
    "        # Get the landmarks/parts for the face in box d.\n",
    "        shape = predictor(image, d);\n",
    "        shape = shape_to_np(shape);\n",
    "\n",
    "    return shape\n",
    "\n",
    "def shape_to_np(shape, dtype=\"int\"):\n",
    "    # initialize the list of (x, y)-coordinates\n",
    "    coords = np.zeros((shape.num_parts, 2), dtype=dtype)\n",
    "    # loop over all facial landmarks and convert them\n",
    "    # to a 2-tuple of (x, y)-coordinates\n",
    "    for i in range(0, shape.num_parts):\n",
    "        coords[i] = (shape.part(i).x, shape.part(i).y)\n",
    "    # return the list of (x, y)-coordinates\n",
    "    return coords\n",
    "\n",
    "def getTilt(keypoints_mn):\n",
    "    # Remove in plane rotation using the eyes\n",
    "    eyes_kp = np.array(keypoints_mn[36:47])\n",
    "    x = eyes_kp[:, 0]\n",
    "    y = -1*eyes_kp[:, 1]\n",
    "    # print('X:', x)\n",
    "    # print('Y:', y)\n",
    "    m = np.polyfit(x, y, 1)\n",
    "    tilt = np.degrees(np.arctan(m[0]))\n",
    "    return tilt\n",
    "\n",
    "def getKeypointFeatures(keypoints):\n",
    "    # Mean Normalize the keypoints wrt the center of the mouth\n",
    "    # Leads to face position invariancy\n",
    "    mouth_kp_mean = np.average(keypoints[48:67], 0)\n",
    "    keypoints_mn = keypoints - mouth_kp_mean\n",
    "\n",
    "    # Remove tilt\n",
    "    x_dash = keypoints_mn[:, 0]\n",
    "    y_dash = keypoints_mn[:, 1]\n",
    "    theta = np.deg2rad(getTilt(keypoints_mn))\n",
    "    c = np.cos(theta);\ts = np.sin(theta)\n",
    "    x = x_dash*c - y_dash*s\t# x = x'cos(theta)-y'sin(theta)\n",
    "    y = x_dash*s + y_dash*c # y = x'sin(theta)+y'cos(theta)\n",
    "    keypoints_tilt = np.hstack((x.reshape((-1,1)), y.reshape((-1,1))))\n",
    "\n",
    "    # Normalize\n",
    "    N = np.linalg.norm(keypoints_tilt, 2)\n",
    "    return [keypoints_tilt/N, N, theta, mouth_kp_mean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dramatic-ancient",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_root = 'F:/dataset/Avatar/Obama/clip/image_crop/00001_1'\n",
    "names = os.listdir(image_root)\n",
    "keypoint_list = []\n",
    "for name in sorted(names):\n",
    "    image_path = os.path.join(image_root,name)\n",
    "    keypoint = get_facial_landmarks(image_path)\n",
    "    # 旋转 并 利用L2进行normalization\n",
    "    l = getKeypointFeatures(keypoint)\n",
    "    unit_kp, N, tilt, mean = l[0], l[1], l[2], l[3]\n",
    "    kp_mouth = unit_kp[48:68]\n",
    "    # [处理过的嘴部特征，L2范数，旋转角度，嘴部特征平局值，处理过的所有特征，处理前的特征]\n",
    "    store_list = [kp_mouth, N, tilt, mean, unit_kp, keypoint]\n",
    "    keypoint_list.append(store_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "retained-insulin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20, 2), 291.66931916808994, -0.04399697319950468, (2,), (68, 2), (68, 2))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_list[0].shape, store_list[1], store_list[2], store_list[3].shape, store_list[4].shape, store_list[5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "boxed-fishing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 2)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kp_mouth.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "internal-excitement",
   "metadata": {},
   "source": [
    "## PCA mouth keypoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "periodic-serial",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list =[]\n",
    "for kp in keypoint_list:\n",
    "    kp_mouth = kp[0]\n",
    "    x = kp_mouth[:, 0].reshape((1, -1))\n",
    "    y = kp_mouth[:, 1].reshape((1, -1))\n",
    "    X = np.hstack((x, y)).reshape((-1)).tolist()\n",
    "    new_list.append(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "chronic-dollar",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(new_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "human-collection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108, 40)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "demonstrated-hierarchy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(n_components=8)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=8)\n",
    "pca.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "strategic-forge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108, 40)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ongoing-corruption",
   "metadata": {},
   "outputs": [],
   "source": [
    "factor = int(np.ceil(100/29.97))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "basic-museum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crazy-marshall",
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame_kp in big_list[key]:\n",
    "    kp_mouth = frame_kp[0]\n",
    "    x = kp_mouth[:, 0].reshape((1, -1))\n",
    "    y = kp_mouth[:, 1].reshape((1, -1))\n",
    "    X = np.hstack((x, y)).reshape((-1)).tolist()\n",
    "    new_list.append(X)\n",
    "\n",
    "X = np.array(new_list)\n",
    "\n",
    "pca = PCA(n_components=8)\n",
    "pca.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italic-fraction",
   "metadata": {},
   "source": [
    "## de-normalize keypoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-baghdad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
